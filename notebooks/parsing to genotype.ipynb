{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occasional-plumbing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bored-disposal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Convert the notebook to /tests directory\n",
    "n_ops = 7\n",
    "n_nodes = 3\n",
    "\n",
    "alpha_normal = []\n",
    "alpha_reduce = []\n",
    "\n",
    "for i in range(n_nodes):\n",
    "    # create alpha parameters over parallel operations\n",
    "    alpha_normal.append(nn.Parameter(\n",
    "        1e-3 * torch.randn(i + 2, n_ops)))\n",
    "    alpha_reduce.append(nn.Parameter(\n",
    "        1e-3 * torch.randn(i + 2, n_ops)))\n",
    "    \n",
    "    \n",
    "[i.shape for i in alpha_normal]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dimensional-portland",
   "metadata": {},
   "outputs": [],
   "source": [
    "PRIMITIVES = [\n",
    "    \"max_pool_3x3\",\n",
    "    \"avg_pool_3x3\",\n",
    "    \"skip_connect\",  # identity\n",
    "    \"conv_1x5_5x1\",\n",
    "    \"conv_3x3\",\n",
    "    \"sep_conv_3x3\",\n",
    "    \"dil_conv_3x3\"\n",
    "]\n",
    "\n",
    "switches_normal = eval(\"[[False, True, True, False, False, True, False], [False, False, True, True, True, False, False], [True, False, True, True, False, False, False], [False, True, True, True, False, False, False], [True, True, True, False, False, False, False], [True, True, True, False, False, False, False], [True, False, False, False, True, True, False], [False, True, True, True, False, False, False], [True, True, True, False, False, False, False]]\")\n",
    "switches_reduce = eval(\"[[True, True, False, False, False, False, False], [True, False, False, True, False, False, False], [True, True, False, False, False, False, False], [False, True, False, False, True, False, False], [True, False, True, False, False, False, False], [False, True, False, False, True, False, False], [False, True, False, True, False, False, False], [False, False, False, True, True, False, False], [True, True, False, False, False, False, False]]\")\n",
    "\n",
    "alpha = [torch.tensor(np.random.normal(0, 0.4, size=(2,3))),\n",
    "         torch.tensor(np.random.normal(0, 0.4, size=(3,3))), \n",
    "         torch.tensor(np.random.normal(0, 0.4, size=(4,3)))]\n",
    "\n",
    "alpha_pairwise = [torch.tensor([1]), \n",
    "                  torch.tensor([0.3346, 0., 0.]), \n",
    "                  torch.tensor([0.0, 0.0, 0.0, 0.1686, 0.0, 0.0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "waiting-nepal",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_tensor_alphas(alpha_concat, nodes=3):\n",
    "    alphas = []\n",
    "    for a_i in get_edge_indices(nodes):\n",
    "        alphas.append(\n",
    "            torch.Tensor(alpha_concat[a_i[0]:a_i[1]]))\n",
    "        \n",
    "    # print(alpha_concat, alphas)\n",
    "    return alphas\n",
    "\n",
    "def get_edge_indices(nodes=3):\n",
    "    # Amount of nodes for each edge\n",
    "    j = [i for i in range(2, nodes+2)] \n",
    "    \n",
    "    prev = 0\n",
    "    indices = []\n",
    "    for i in j:\n",
    "        if prev != 0:\n",
    "            indices.append((sum(j[:j.index(prev)+1]), \n",
    "                            sum(j[:j.index(i)+1])))\n",
    "        else:\n",
    "            indices.append((0, sum(j[:j.index(i)+1])))\n",
    "        prev = i\n",
    "    return indices\n",
    "\n",
    "def parse(alpha, switches, k, primitives=PRIMITIVES):\n",
    "    gene = []\n",
    "    j = 0\n",
    "    \n",
    "    for edge_i, edges in enumerate(alpha):\n",
    "        # These primitive indices don't correspond to the actual\n",
    "        # primitive. k=1 here.\n",
    "        edge_max, primitive_indices = torch.topk(edges[:, :], 1)\n",
    "        topk_edge_values, topk_edge_indices = torch.topk(edge_max.view(-1), k)\n",
    "        \n",
    "        # Primitive indices which are enabled\n",
    "        primitives_enabled = []\n",
    "        for _ in range(len(edges)):\n",
    "            prim_enabled_indices = np.where(switches[j])[0]\n",
    "            # The primitive operations which are enabled\n",
    "            primitives_enabled.append([\n",
    "                primitives[i] for i in prim_enabled_indices])\n",
    "            j += 1\n",
    "        \n",
    "        # For each edge the highest alpha primitive indice\n",
    "        node_gene = []\n",
    "        for edge_idx in topk_edge_indices:\n",
    "            prim_idx = primitive_indices[edge_idx]\n",
    "            # print(edges)\n",
    "            # print(primitives_enabled)\n",
    "            # print(edge_idx, prim_idx[0])\n",
    "            # print(primitives_enabled[edge_idx][prim_idx[0]])\n",
    "            prim = primitives_enabled[edge_idx][prim_idx[0]]\n",
    "            node_gene.append((prim, edge_idx.item()))\n",
    "\n",
    "        gene.append(node_gene)\n",
    "    return gene\n",
    "\n",
    "parse(alpha, switches_normal, k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demanding-astrology",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gene = [[('sep_conv_3x3', 0), ('conv_1x5_5x1', 1)],\n",
    "#  [('max_pool_3x3', 0), ('skip_connect', 2)],\n",
    "#  [('skip_connect', 0), ('skip_connect', 2)]]\n",
    "[['max_pool_3x3', 'skip_connect', 'conv_1x5_5x1'], \n",
    " ['avg_pool_3x3', 'conv_1x5_5x1'], \n",
    " ['max_pool_3x3', 'avg_pool_3x3', 'skip_connect']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southwest-aruba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "alpha = [torch.tensor(np.random.normal(0, 0.4, size=(2,3))).cuda(),\n",
    "         torch.tensor(np.random.normal(0, 0.4, size=(3,3))).cuda(), \n",
    "         torch.tensor(np.random.normal(0, 0.4, size=(4,3))).cuda()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aging-bumper",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def limit_skip_connections(alphas, switches, num_of_sk=2, nodes=3, \n",
    "                           k=2, primitives=PRIMITIVES):\n",
    "    sk_idx = primitives.index(\"skip_connect\")\n",
    "    alphas = [a.detach().numpy() for a in alphas]\n",
    "    alpha_concat = np.concatenate(alphas, axis=0)\n",
    "    \n",
    "    # skip-connections alpha indices\n",
    "    # edge index, skip-connection alpha_index\n",
    "    sk_indices = []\n",
    "    # alphas corresponding to the skip-connections\n",
    "    sk_alphas = []\n",
    "    for i, sw in enumerate(switches):\n",
    "        prim_indices = np.where(sw)[0]\n",
    "        # skip-connection index of alpha\n",
    "        sk_index = np.where(prim_indices==sk_idx)[0].tolist()\n",
    "        sk_indices.append([i, sk_index])\n",
    "\n",
    "        if len(sk_index) > 0:\n",
    "            sk_alphas.append(alpha_concat[i][sk_index][0])\n",
    "        else: # If the skip-connection is not enabled, set to infinity.\n",
    "            sk_alphas.append(float(\"inf\"))\n",
    "        \n",
    "    # Number of skip-connections enabled in switches\n",
    "    # TODO: refactor to check based on gene\n",
    "    # num_sk_enabled = sum(np.array(switches)[:, sk_idx])\n",
    "    gene = parse(alphas, switches, k=k)\n",
    "    num_sk_enabled = sum([1 for edge in gene \n",
    "                          for op in edge if op[0] == \"skip_connect\"])\n",
    "\n",
    "    sk_a = np.array(sk_alphas)\n",
    "    \n",
    "    if num_sk_enabled < num_of_sk:\n",
    "        alphas = convert_tensor_alphas(alpha_concat)\n",
    "        gene = parse(alphas, switches, k=k)\n",
    "        return gene\n",
    "    else:\n",
    "        it = 0\n",
    "        while num_sk_enabled > num_of_sk:\n",
    "            print(\"########## iteration\", it)\n",
    "            it += 1\n",
    "            # Pick skip-connection index with lowest alpha \n",
    "            # value\n",
    "            idx = np.argmin(sk_a)\n",
    "            sk_a[idx] = float(\"inf\")\n",
    "            \n",
    "            # row index and alpha index\n",
    "            row_idx, alpha_idx = sk_indices[idx][0], sk_indices[idx][1][0]\n",
    "            \n",
    "            # Set switch sk index to False\n",
    "            # switches[row_idx][sk_idx] = False\n",
    "        \n",
    "            # set alphas to -inf to make sure, prevent it from\n",
    "            # being picked. \n",
    "            alpha_concat[row_idx][alpha_idx] = float(\"-inf\")\n",
    "            alphas = convert_tensor_alphas(alpha_concat)\n",
    "            \n",
    "            gene = parse(alphas, switches, k=k)\n",
    "            num_sk_enabled = sum([1 for edge in gene \n",
    "                                  for op in edge if op[0] == \"skip_connect\"])\n",
    "            \n",
    "            if num_sk_enabled <= num_of_sk:\n",
    "                # return the new switches\n",
    "                return gene\n",
    "\n",
    "limit_skip_connections(alpha, switches_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "binary-march",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene = []\n",
    "k = 2\n",
    "j = 0\n",
    "\n",
    "for edge_i, edges in enumerate(alpha):\n",
    "    # TODO: These primitive indices don't correspond to the actual\n",
    "    # primitive. k=1 here.\n",
    "    edge_max, _ = torch.topk(edges[:, :], 1)\n",
    "    \n",
    "    topk_edge_values, topk_edge_indices = torch.topk(edge_max.view(-1), k)\n",
    "    \n",
    "    # Primitive indices which are enabled\n",
    "    primitives_enabled = []\n",
    "    for _ in range(len(edges)):\n",
    "        prim_indices = np.where(switches[j])[0]\n",
    "        # The primitive operations which are enabled\n",
    "        primitives_enabled.append([primitives[i] for i in prim_indices])\n",
    "        j += 1\n",
    "\n",
    "    # For each edge the highest alpha primitive indice\n",
    "    node_gene = []\n",
    "    for edge_idx in topk_edge_indices:\n",
    "        prim = primitives_enabled[edge_idx][prim_idx]\n",
    "        node_gene.append((prim, edge_idx.item()))\n",
    "        \n",
    "    gene.append(node_gene)\n",
    "\n",
    "gene"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('meta': conda)",
   "language": "python",
   "name": "python3710jvsc74a57bd0b1d57bbef129b95556cf4acac245eaf539d69532a51fcbf5e76efb5e83c89ceb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
