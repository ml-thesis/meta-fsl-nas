{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 478,
   "id": "green-expansion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 1.9719e-03, -2.2639e-04, -5.7323e-05,  3.8733e-04, -1.0382e-03,\n",
       "          4.6009e-04, -1.5278e-04], grad_fn=<SelectBackward>),\n",
       " tensor([0.1431, 0.1428, 0.1428, 0.1429, 0.1427, 0.1429, 0.1428],\n",
       "        grad_fn=<SelectBackward>))"
      ]
     },
     "execution_count": 478,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import scipy.special\n",
    "\n",
    "n_ops = 7\n",
    "n_nodes = 3\n",
    "\n",
    "alphas = []\n",
    "alpha_pw_normal = []\n",
    "\n",
    "norm_alphas = []\n",
    "\n",
    "for i in range(n_nodes):\n",
    "    a = nn.Parameter(1e-3 * torch.randn(i + 2, n_ops))\n",
    "    num_comb = int(scipy.special.binom(i + 2, 2))\n",
    "    alpha_pw_normal.append(nn.Parameter(1e-3 * torch.randn(num_comb)))\n",
    "    \n",
    "    alphas.append(a)\n",
    "    norm_alphas.append(F.softmax(a, dim=-1))\n",
    "    \n",
    "    \n",
    "alphas[0][0], norm_alphas[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "id": "organized-thong",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 482,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(scipy.special.binom(1 + 2, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "id": "african-wallace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 1.9719e-03, -2.2639e-04, -5.7323e-05,  3.8733e-04, -1.0382e-03,\n",
       "           4.6009e-04, -1.5278e-04],\n",
       "         [ 7.9759e-04, -1.1061e-03,  8.7072e-04,  8.7971e-05,  7.9254e-04,\n",
       "           2.2627e-04,  1.5051e-04]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 1.4632e-03, -5.8189e-04, -1.0868e-03, -7.3043e-04,  8.1603e-04,\n",
       "          -1.1836e-03, -1.0569e-03],\n",
       "         [-1.0162e-03,  9.6582e-04,  1.7232e-03, -1.1815e-03,  1.0269e-03,\n",
       "           3.7533e-04,  1.1480e-03],\n",
       "         [-1.0145e-03, -7.9381e-04, -3.0377e-04,  9.3046e-04, -6.5374e-05,\n",
       "           1.2392e-04,  1.6889e-03]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 5.3051e-05, -4.3119e-04, -5.6323e-06, -1.6468e-04,  7.2717e-04,\n",
       "           1.2750e-03,  6.7625e-04],\n",
       "         [ 3.9846e-04, -3.0487e-04, -8.0514e-04,  1.9182e-03,  7.5514e-04,\n",
       "           1.6797e-04,  1.8888e-04],\n",
       "         [ 1.1912e-03,  1.1795e-03, -5.1644e-04, -9.3776e-04, -1.7412e-03,\n",
       "          -6.6687e-04,  1.3030e-04],\n",
       "         [ 1.0786e-03,  2.0974e-03,  5.0019e-04, -1.3981e-03, -6.1657e-04,\n",
       "           2.1141e-04, -1.0523e-04]], requires_grad=True)]"
      ]
     },
     "execution_count": 480,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "id": "patent-bread",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([0.0004], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([2.0163e-03, 1.5127e-03, 2.0280e-05], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0005,  0.0003,  0.0018,  0.0009,  0.0004,  0.0004],\n",
       "        requires_grad=True)]"
      ]
     },
     "execution_count": 479,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_pw_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "other-saturn",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0013, grad_fn=<SumBackward0>),\n",
       " tensor(0.0013, grad_fn=<SumBackward0>))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = calc_C_term(alphas[0][0])\n",
    "\n",
    "# C_term\n",
    "torch.sum(inverse_softmax(norm_alphas[0][0], C)), torch.sum(alphas[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "outdoor-tackle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.0008,  0.0017, -0.0001,  0.0014, -0.0016, -0.0014,  0.0006],\n",
       "        grad_fn=<AddBackward0>),\n",
       " tensor([0.1429, 0.1431, 0.1428, 0.1430, 0.1426, 0.1426, 0.1429],\n",
       "        grad_fn=<SoftmaxBackward>))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inverse_softmax(norm_alphas[0][0], C), F.softmax(inverse_softmax(norm_alphas[0][0], C), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "configured-quarter",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now, increasing the alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "conscious-publicity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4427, 0.0928, 0.0926, 0.0928, 0.0931, 0.0929, 0.0932],\n",
       "       grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "increase_p = 0.3\n",
    "norm_alphas[0][0][0] += increase_p\n",
    "\n",
    "for i in range(1, 7):\n",
    "    norm_alphas[0][0][i] -= increase_p/(n_ops-1)\n",
    "\n",
    "norm_alphas[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "established-alliance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.1305, -0.4320, -0.4345, -0.4315, -0.4288, -0.4309, -0.4276],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inverse_softmax(norm_alphas[0][0], C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "russian-formation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "id": "going-process",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_softmax(x, C):\n",
    "    return torch.log(x) + C\n",
    "\n",
    "def calc_C_term(a):\n",
    "    e_xi = torch.exp(a)\n",
    "    sum_i = torch.sum(e_xi)\n",
    "    c_i = torch.log(sum_i)\n",
    "    return c_i\n",
    "\n",
    "# TODO: with torch no grad\n",
    "# norm_alphas, alphas, n_ops\n",
    "prob = 0.3\n",
    "\n",
    "\n",
    "# Limits increase, \n",
    "def increase_op(row_idx, edge_idx, op_idx):\n",
    "    C = calc_C_term(alphas[0][0])\n",
    "    \n",
    "    if norm_alphas[row_idx][edge_idx][op_idx] + prob < 1.0:\n",
    "        with torch.no_grad():\n",
    "            norm_alphas[row_idx][edge_idx][op_idx] += prob\n",
    "\n",
    "        # Align the other probabilities by lowering them\n",
    "        indices = np.delete(np.arange(n_ops), op_idx)\n",
    "        with torch.no_grad():\n",
    "            norm_alphas[0][0][indices] -= prob/(n_ops-1)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        alphas[0][0] = inverse_softmax(norm_alphas[0][0], C)\n",
    "    print(alphas[0][0])\n",
    "    \n",
    "    norm_alphas[0][0] = F.softmax(alphas[0][0], dim=-1)\n",
    "    print(norm_alphas[0][0])\n",
    "    # return alpha\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "advanced-diving",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.1311, -0.4315, -0.4314, -0.4287, -0.4320, -0.4305, -0.4316],\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor([0.4428, 0.0928, 0.0928, 0.0931, 0.0928, 0.0929, 0.0928],\n",
      "       grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "increase_op(0, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "impressed-remainder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.6484, -1.2053, -1.2051, -1.1992, -1.2063, -1.2030, -1.2055],\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor([0.7428, 0.0428, 0.0428, 0.0431, 0.0428, 0.0429, 0.0428],\n",
      "       grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "increase_op(0, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "whole-march",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 3, 4, 5, 6])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.delete(np.arange(n_ops), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "improved-japanese",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_alphas[0][0][np.delete(np.arange(n_ops), 2)] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "smooth-chase",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.0429, -0.0069, -0.0070, -0.0074, -0.0070, -0.0073, -0.0072],\n",
       "       grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_alphas[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "sophisticated-record",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2.0429,  0.9931, -0.0070,  0.9926,  0.9930,  0.9927,  0.9928],\n",
       "       grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_alphas[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organized-specialist",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Test edge cases#\n",
    "# TODO: Same starting temperature?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "breeding-spouse",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unusual-digit",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "id": "exciting-remainder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orig tensor([ 1.1632, -0.5108, -1.6094, -0.9163,  0.8755,  1.3083, -2.3026],\n",
      "       grad_fn=<SelectBackward>)\n",
      "norm tensor([0.3019, 0.0566, 0.0189, 0.0377, 0.2264, 0.3491, 0.0094],\n",
      "       grad_fn=<SelectBackward>) tensor(1.0000, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "n_ops = 7\n",
    "n_nodes = 3\n",
    "\n",
    "alphas = []\n",
    "norm_alphas = []\n",
    "\n",
    "\n",
    "for i in range(n_nodes):\n",
    "    a = nn.Parameter(\n",
    "        1e-3 * torch.randn(i + 2, n_ops))\n",
    "    alphas.append(a)\n",
    "    norm_alphas.append(F.softmax(a, dim=-1))\n",
    "    \n",
    "    \n",
    "alphas[0][0], norm_alphas[0][0]\n",
    "\n",
    "\n",
    "def inverse_softmax(x, C):\n",
    "    return torch.log(x) + C\n",
    "\n",
    "def calc_C_term(a):\n",
    "#     e_xi = torch.exp(a)\n",
    "#     sum_i = torch.sum(e_xi)\n",
    "#     c_i = torch.log(sum_i)\n",
    "#     return c_i\n",
    "    \n",
    "    return torch.log(torch.tensor([10.]))[0]\n",
    "\n",
    "# TODO: with torch no grad\n",
    "# norm_alphas, alphas, n_ops\n",
    "\n",
    "\n",
    "# Fully, allows increase \n",
    "def increase_op(row_idx, edge_idx, op_idx, prob=0.3, n_ops=7):\n",
    "    C = calc_C_term(alphas[row_idx][edge_idx])\n",
    "    \n",
    "    # Set short-hands\n",
    "#     curr_op = norm_alphas[row_idx][edge_idx][op_idx]\n",
    "#     curr_edge = norm_alphas[row_idx][edge_idx]\n",
    "    curr_op = torch.tensor([0.32, 0.05, 0.01, 0.03, 0.23, 0.36, 0.00])[op_idx]\n",
    "    curr_edge = torch.tensor([0.32, 0.05, 0.01, 0.03, 0.23, 0.36, 0.00])\n",
    "    \n",
    "    \n",
    "    # Allow for increasing to 0.99\n",
    "    if curr_op + prob > 1.0:\n",
    "        surplus = curr_op + prob - 0.99\n",
    "        prob -= surplus\n",
    "    \n",
    "    if curr_op + prob < 1.0:\n",
    "        # Increase chosen op\n",
    "        with torch.no_grad():\n",
    "            curr_op += prob\n",
    "\n",
    "        # Align the other probabilities by lowering them\n",
    "#         indices = np.delete(np.arange(n_ops), op_idx)\n",
    "        with torch.no_grad():\n",
    "            curr_edge += 0.01\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        alphas[row_idx][edge_idx] = inverse_softmax(curr_edge, C)\n",
    "        \n",
    "        \n",
    "    # Display for testing\n",
    "    print(\"orig\", alphas[row_idx][edge_idx])\n",
    "    norm_alphas[row_idx][edge_idx] = F.softmax(alphas[row_idx][edge_idx], dim=-1)\n",
    "    print(\"norm\", norm_alphas[row_idx][edge_idx], torch.sum(norm_alphas[row_idx][edge_idx]))\n",
    "    \n",
    "    \n",
    "    \n",
    "def decrease_op(row_idx, edge_idx, op_idx, prob=0.3, n_ops=7):\n",
    "    C = calc_C_term(alphas[row_idx][edge_idx])\n",
    "    \n",
    "    # Set short-hands\n",
    "    curr_op = norm_alphas[row_idx][edge_idx][op_idx]\n",
    "    curr_edge = norm_alphas[row_idx][edge_idx]\n",
    "    \n",
    "    # Allow for increasing to 0.99\n",
    "    if curr_op - prob < 0.0:\n",
    "        surplus = prob - curr_op + 0.01\n",
    "        print(surplus)\n",
    "        prob -= surplus\n",
    "        print(prob)\n",
    "    \n",
    "    if curr_op - prob > 0.0:\n",
    "        # Increase chosen op\n",
    "        with torch.no_grad():\n",
    "            curr_op -= prob\n",
    "\n",
    "        # Align the other probabilities by lowering them\n",
    "        indices = np.arange(n_ops), op_idx\n",
    "        with torch.no_grad():\n",
    "            norm_alphas[row_idx][edge_idx] += 0.01\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        alphas[row_idx][edge_idx] = inverse_softmax(curr_edge, C)\n",
    "        \n",
    "        \n",
    "    # Display for testing\n",
    "    print(\"orig\", alphas[row_idx][edge_idx])\n",
    "    norm_alphas[row_idx][edge_idx] = F.softmax(alphas[row_idx][edge_idx], dim=-1)\n",
    "    print(\"norm\", norm_alphas[row_idx][edge_idx], torch.sum(norm_alphas[row_idx][edge_idx]))\n",
    "    \n",
    "increase_op(0, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "finnish-photograph",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3026)"
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "experienced-table",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3200, 0.0500, 0.0100, 0.0300, 0.2300, 0.3600, 0.0000])"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_a = torch.tensor([0.32, 0.05, 0.01, 0.03, 0.23, 0.36, 0.01])\n",
    "# TODO: Prevent value from being 0\n",
    "test_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "tender-webster",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orig tensor([ 0.9531, -0.7517, -1.8503, -1.1571,  0.6346,  1.0401, -2.5434],\n",
      "       grad_fn=<SelectBackward>)\n",
      "norm tensor([0.3113, 0.0566, 0.0189, 0.0377, 0.2264, 0.3396, 0.0094],\n",
      "       grad_fn=<SelectBackward>) tensor(1.0000, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "increase_op(0, 0, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "wired-lunch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orig tensor([ 1.1318e+00,  1.3165e+00,  1.5151e+00,  2.2275e-03,  1.4901e-04,\n",
      "        -9.8681e-04, -4.2415e-04], grad_fn=<SelectBackward>)\n",
      "norm tensor([0.2016, 0.2425, 0.2958, 0.0652, 0.0650, 0.0649, 0.0650],\n",
      "       grad_fn=<SelectBackward>) tensor(1.0000, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "increase_op(0, 0, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "driven-settle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orig tensor([2.0433e+00, 3.5510e+00, 1.5151e+00, 2.2273e-03, 1.4877e-04, 4.4984e+00,\n",
      "        3.1836e+00], grad_fn=<SelectBackward>)\n",
      "norm tensor([0.0473, 0.2136, 0.0279, 0.0061, 0.0061, 0.5510, 0.1479],\n",
      "       grad_fn=<SelectBackward>) tensor(1.0000, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "increase_op(0, 0, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "id": "satellite-customs",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Test this\n",
    "# for i in range(100000):\n",
    "#     decrease_op(0, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "id": "sonic-november",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[0.0188, 0.1635, 0.1635, 0.1635, 0.1635, 0.1635, 0.1635],\n",
       "         [0.1427, 0.1428, 0.1429, 0.1430, 0.1428, 0.1429, 0.1429]],\n",
       "        grad_fn=<CopySlices>),\n",
       " tensor([[0.1429, 0.1427, 0.1428, 0.1430, 0.1429, 0.1428, 0.1428],\n",
       "         [0.1428, 0.1431, 0.1426, 0.1426, 0.1430, 0.1429, 0.1430],\n",
       "         [0.1428, 0.1427, 0.1428, 0.1428, 0.1429, 0.1428, 0.1430]],\n",
       "        grad_fn=<SoftmaxBackward>),\n",
       " tensor([[0.1430, 0.1429, 0.1429, 0.1429, 0.1428, 0.1426, 0.1430],\n",
       "         [0.1431, 0.1428, 0.1426, 0.1430, 0.1428, 0.1427, 0.1429],\n",
       "         [0.1428, 0.1428, 0.1430, 0.1428, 0.1428, 0.1430, 0.1429],\n",
       "         [0.1428, 0.1430, 0.1429, 0.1429, 0.1428, 0.1429, 0.1426]],\n",
       "        grad_fn=<SoftmaxBackward>)]"
      ]
     },
     "execution_count": 476,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "id": "consistent-recipe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[0.0188, 0.1635, 0.1635, 0.1635, 0.1635, 0.1635, 0.1635],\n",
       "         [0.1427, 0.1428, 0.1429, 0.1430, 0.1428, 0.1429, 0.1429]]),\n",
       " tensor([[0.1429, 0.1427, 0.1428, 0.1430, 0.1429, 0.1428, 0.1428],\n",
       "         [0.1428, 0.1431, 0.1426, 0.1426, 0.1430, 0.1429, 0.1430],\n",
       "         [0.1428, 0.1427, 0.1428, 0.1428, 0.1429, 0.1428, 0.1430]]),\n",
       " tensor([[0.1430, 0.1429, 0.1429, 0.1429, 0.1428, 0.1426, 0.1430],\n",
       "         [0.1431, 0.1428, 0.1426, 0.1430, 0.1428, 0.1427, 0.1429],\n",
       "         [0.1428, 0.1428, 0.1430, 0.1428, 0.1428, 0.1430, 0.1429],\n",
       "         [0.1428, 0.1430, 0.1429, 0.1429, 0.1428, 0.1429, 0.1426]])]"
      ]
     },
     "execution_count": 472,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "a = [copy.deepcopy(alpha.detach()) for alpha in norm_alphas]\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "id": "stylish-greensboro",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[0.0188, 0.1635, 0.1635, 0.1635, 0.1635, 0.1635, 0.1635],\n",
       "         [0.1427, 0.1428, 0.1429, 0.1430, 0.1428, 0.1429, 0.1429]]),\n",
       " tensor([[0.1429, 0.1427, 0.1428, 0.1430, 0.1429, 0.1428, 0.1428],\n",
       "         [0.1428, 0.1431, 0.1426, 0.1426, 0.1430, 0.1429, 0.1430],\n",
       "         [0.1428, 0.1427, 0.1428, 0.1428, 0.1429, 0.1428, 0.1430]]),\n",
       " tensor([[0.1430, 0.1429, 0.1429, 0.1429, 0.1428, 0.1426, 0.1430],\n",
       "         [0.1431, 0.1428, 0.1426, 0.1430, 0.1428, 0.1427, 0.1429],\n",
       "         [0.1428, 0.1428, 0.1430, 0.1428, 0.1428, 0.1430, 0.1429],\n",
       "         [0.1428, 0.1430, 0.1429, 0.1429, 0.1428, 0.1429, 0.1426]])]"
      ]
     },
     "execution_count": 473,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = a\n",
    "\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "id": "atomic-nurse",
   "metadata": {},
   "outputs": [],
   "source": [
    "b[0][0][0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "id": "closing-delicious",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[1.0000, 0.1635, 0.1635, 0.1635, 0.1635, 0.1635, 0.1635],\n",
       "         [0.1427, 0.1428, 0.1429, 0.1430, 0.1428, 0.1429, 0.1429]]),\n",
       " tensor([[0.1429, 0.1427, 0.1428, 0.1430, 0.1429, 0.1428, 0.1428],\n",
       "         [0.1428, 0.1431, 0.1426, 0.1426, 0.1430, 0.1429, 0.1430],\n",
       "         [0.1428, 0.1427, 0.1428, 0.1428, 0.1429, 0.1428, 0.1430]]),\n",
       " tensor([[0.1430, 0.1429, 0.1429, 0.1429, 0.1428, 0.1426, 0.1430],\n",
       "         [0.1431, 0.1428, 0.1426, 0.1430, 0.1428, 0.1427, 0.1429],\n",
       "         [0.1428, 0.1428, 0.1430, 0.1428, 0.1428, 0.1430, 0.1429],\n",
       "         [0.1428, 0.1430, 0.1429, 0.1429, 0.1428, 0.1429, 0.1426]])]"
      ]
     },
     "execution_count": 475,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "difficult-prophet",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acceptable-upper",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "humanitarian-vocabulary",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "insured-antigua",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('meta': conda)",
   "language": "python",
   "name": "python3710jvsc74a57bd0b1d57bbef129b95556cf4acac245eaf539d69532a51fcbf5e76efb5e83c89ceb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
